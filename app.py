# app.py
import streamlit as st
import pandas as pd
import numpy as np
import joblib
from pathlib import Path
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.pipeline import Pipeline

from src.config import (
    RAW_DIR, MODELS_DIR, TARGET_COL,
    DEFAULT_FINAL_COLS, OPTIONAL_COLS, LEAKAGE_OR_DROP_COLS
)
from src.io import load_raw_files
from src.preprocess import preprocess_all
from src.features import summary_table, severe_rate_by
from src.models import build_logistic, build_random_forest
from src.evaluate import evaluate_binary

plt.rcParams["font.family"] = "Malgun Gothic"
plt.rcParams["axes.unicode_minus"] = False

# -----------------------------
# Streamlit ì„¤ì •
# -----------------------------
st.set_page_config(page_title="êµí†µì‚¬ê³  ì¤‘ëŒ€ì‚¬ê³  ì˜ˆì¸¡", layout="wide")
st.title("ğŸš¦ êµí†µì‚¬ê³  ì¤‘ëŒ€ì‚¬ê³  ì˜ˆì¸¡ (Streamlit)")

MODEL_PATH = MODELS_DIR / "best_model.pkl"
MODELS_DIR.mkdir(exist_ok=True, parents=True)

# -----------------------------
# ìºì‹œ: ë°ì´í„° ë¡œë”©/ì „ì²˜ë¦¬
# -----------------------------
@st.cache_data
def load_and_preprocess():
    df = load_raw_files(RAW_DIR, patterns=["*.csv"])
    df = preprocess_all(df)
    return df

# -----------------------------
# ìºì‹œ: ëª¨ë¸ ë¡œë“œ (ì•± ì‹¤í–‰ ì¤‘ 1íšŒ)
# -----------------------------
@st.cache_resource
def load_saved_model(path: str):
    p = Path(path)
    if p.exists():
        return joblib.load(p)
    return None

# -----------------------------
# ìœ í‹¸: íŒŒì´í”„ë¼ì¸ ìƒì„±
# -----------------------------
def build_pipeline(model, cat_cols):
    preprocess = ColumnTransformer(
        transformers=[("cat", OneHotEncoder(handle_unknown="ignore"), cat_cols)]
    )
    pipe = Pipeline([("preprocess", preprocess), ("model", model)])
    return pipe

def try_build_xgboost(scale_pos_weight: float):
    try:
        from src.models import build_xgboost
        return build_xgboost(scale_pos_weight)
    except Exception:
        return None

# -----------------------------
# ìœ í‹¸: feature importance ì¶”ì¶œ
# -----------------------------
def get_encoded_feature_names(pipe):
    # pipe: Pipeline(preprocess=ColumnTransformer, model=...)
    ct = pipe.named_steps["preprocess"]
    names = ct.get_feature_names_out()
    # ë³´ê¸° ì¢‹ê²Œ prefix ì •ë¦¬ (cat__ ì œê±°)
    names = [n.replace("cat__", "") for n in names]
    return names


def compute_feature_importance(pipe: Pipeline, cat_cols: list[str]) -> pd.DataFrame:
    """
    ëª¨ë¸ë³„ ì¤‘ìš”ë„:
    - RF/XGB: feature_importances_
    - Logistic: |coef_| í•©(ë‹¤ì¤‘ í´ë˜ìŠ¤ ë°©ì–´)
    """
    model = pipe.named_steps["model"]
    feat_names = get_encoded_feature_names(pipe)

    if hasattr(model, "feature_importances_"):
        imp = np.asarray(model.feature_importances_, dtype=float)
    elif hasattr(model, "coef_"):
        coef = np.asarray(model.coef_, dtype=float)
        if coef.ndim == 2:
            imp = np.abs(coef).sum(axis=0)
        else:
            imp = np.abs(coef)
    else:
        imp = np.zeros(len(feat_names), dtype=float)

    imp_df = pd.DataFrame({"feature": feat_names, "importance": imp})
    imp_df["base_col"] = imp_df["feature"].astype(str).str.split("_", n=1).str[0]
    col_imp = (
        imp_df.groupby("base_col")["importance"]
        .sum()
        .reset_index()
        .rename(columns={"importance": "model_importance"})
        .sort_values("model_importance", ascending=False)
        .reset_index(drop=True)
    )
    return imp_df.sort_values("importance", ascending=False).reset_index(drop=True), col_imp

def ensure_model_loaded_to_state():
    """ì•± ì‹œì‘ ì‹œ ì €ì¥ ëª¨ë¸ì´ ìˆìœ¼ë©´ session_stateì— ì˜¬ë ¤ë‘ê¸°"""
    if "model" not in st.session_state or st.session_state["model"] is None:
        saved = load_saved_model(str(MODEL_PATH))
        if saved is not None:
            st.session_state["model"] = saved
            st.session_state["model_name"] = "best_model.pkl(loaded)"
            st.session_state["model_path"] = str(MODEL_PATH)

# -----------------------------
# ë°ì´í„° ì¤€ë¹„
# -----------------------------
with st.spinner("ë°ì´í„° ë¡œë”©/ì „ì²˜ë¦¬ ì¤‘..."):
    acc = load_and_preprocess()
ensure_model_loaded_to_state()

# -----------------------------
# íƒ­ 6ê°œ êµ¬ì„±
# -----------------------------
t1, t2, t3, t4, t5, t6 = st.tabs([
    "1) ë°ì´í„° ê°œìš”",
    "2) ë²”ì£¼ë³„ ì¤‘ëŒ€ì‚¬ê³ ìœ¨",
    "3) ëª¨ë¸ í•™ìŠµ/ì„±ëŠ¥ ë¹„êµ",
    "4) ì˜ˆì¸¡",
    "5) Feature Importance",
    "6) ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸°",
])

# =========================================================
# 1) ë°ì´í„° ê°œìš”
# =========================================================
with t1:
    st.subheader("ë°ì´í„° ê°œìš”")

    c1, c2 = st.columns([1, 1])
    with c1:
        st.write("**ë°ì´í„° êµ¬ì¡°/ê²°ì¸¡ì¹˜ ìš”ì•½**")
        st.dataframe(summary_table(acc), use_container_width=True)
    with c2:
        st.write("**ê¸°ë³¸ í†µê³„**")
        st.metric("ì´ í–‰ ìˆ˜", f"{len(acc):,}")
        st.metric("ì¤‘ëŒ€ì‚¬ê³  ë¹„ìœ¨(Mean)", f"{float(acc[TARGET_COL].mean()*100):.1f}%")
        st.write("- íƒ€ê²Ÿ ì •ì˜: (ì‚¬ë§ììˆ˜ + ì¤‘ìƒììˆ˜) â‰¥ 1 â†’ ì¤‘ëŒ€ì‚¬ê³ =1")
        

    st.divider()
    st.write("**ëˆ„ìˆ˜/ì‹ë³„ì/ì‚¬í›„ì •ë³´ë¡œ ì œì™¸ í›„ë³´ ì»¬ëŸ¼(ì°¸ê³ )**")
    st.write([c for c in LEAKAGE_OR_DROP_COLS if c in acc.columns])

# =========================================================
# 2) ë²”ì£¼ë³„ ì¤‘ëŒ€ì‚¬ê³ ìœ¨
# =========================================================
with t2:
    st.subheader("ë²”ì£¼ë³„ ì¤‘ëŒ€ì‚¬ê³ ìœ¨ ë¹„êµ")

    # ë²”ì£¼í˜• í›„ë³´
    cat_candidates = [c for c in acc.columns if acc[c].dtype == "object"]
    default_idx = cat_candidates.index("ì‚¬ê³ ìœ í˜•") if "ì‚¬ê³ ìœ í˜•" in cat_candidates else 0
    col = st.selectbox("ë³€ìˆ˜ ì„ íƒ", cat_candidates, index=default_idx)

    min_count = st.slider("ìµœì†Œ í‘œë³¸ìˆ˜(min_count) ì´í•˜ ë²”ì£¼ëŠ” ì œì™¸", 10, 500, 50, 10)

    rate_df = severe_rate_by(acc, col, target=TARGET_COL, min_count=min_count)
    st.dataframe(rate_df.head(30), use_container_width=True)

    if len(rate_df) > 0:
        topn = st.slider("ê·¸ë˜í”„ í‘œì‹œ ë²”ì£¼ ìˆ˜(ìƒìœ„)", 5, 30, 12, 1)
        plot_df = rate_df.head(topn).sort_values("severe_rate")
        fig = plt.figure(figsize=(8, 5))
        plt.barh(plot_df[col].astype(str), plot_df["severe_rate"])
        plt.title(f"{col}ë³„ ì¤‘ëŒ€ì‚¬ê³ ìœ¨ (ìƒìœ„ {topn})")
        plt.xlabel("ì¤‘ëŒ€ì‚¬ê³ ìœ¨")
        plt.tight_layout()
        st.pyplot(fig)

# =========================================================
# 3) ëª¨ë¸ í•™ìŠµ/ì„±ëŠ¥ ë¹„êµ
# =========================================================
with t3:
    st.subheader("ëª¨ë¸ í•™ìŠµ ë° ì„±ëŠ¥ ë¹„êµ (Logistic / RandomForest / XGBoost)")

    st.write("**í•™ìŠµ ë³€ìˆ˜ ì„ íƒ**")
    use_optional = st.checkbox("ë³´ì¡° ë³€ìˆ˜ë„ í¬í•¨(ì£¼ì•¼/ë…¸ë©´/ê¸°ìƒ ë“±)", value=False)
    feature_cols = DEFAULT_FINAL_COLS + OPTIONAL_COLS if use_optional else DEFAULT_FINAL_COLS
    feature_cols = [c for c in feature_cols if c in acc.columns]

    st.caption(f"ì„ íƒëœ ë³€ìˆ˜: {feature_cols}")

    test_size = st.slider("test_size", 0.1, 0.4, 0.2, 0.05)
    metric_pick = st.selectbox("Best ëª¨ë¸ ê¸°ì¤€", ["f1", "auc"], index=0)

    with st.expander("ì™œ ì¼ë¶€ ì»¬ëŸ¼ì€ í•™ìŠµì—ì„œ ì œì™¸í•˜ë‚˜ìš”?"):
        st.write("- ì‚¬ê³  ë°œìƒ ì‹œì ì— ì•Œê¸° ì–´ë ¤ìš´ ê²°ê³¼/ì‚¬í›„ ì •ë³´ ë˜ëŠ” ì‹ë³„ì(êµ¬ë¶„ë²ˆí˜¸) ë“±ì€ ëª¨ë¸ì´ ë‹µì„ 'ë¯¸ë¦¬' ì•Œì•„ë²„ë¦¬ëŠ” ëˆ„ìˆ˜ ìœ„í—˜ì´ ìˆìŠµë‹ˆë‹¤.")
        st.write([c for c in LEAKAGE_OR_DROP_COLS if c in acc.columns])

    run_train = st.button("âœ… 3ê°œ ëª¨ë¸ í•™ìŠµ/í‰ê°€ ì‹¤í–‰", type="primary")

    if run_train:
        X = acc[feature_cols].copy()
        y = acc[TARGET_COL].copy()

        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=42, stratify=y
        )

        results = []

        # Logistic
        lr = build_logistic()
        lr_pipe = build_pipeline(lr, feature_cols)
        with st.spinner("Logistic Regression í•™ìŠµ ì¤‘..."):
            lr_pipe.fit(X_train, y_train)
        lr_metrics = evaluate_binary(lr_pipe, X_test, y_test)
        results.append(("LogisticRegression", lr_pipe, lr_metrics))

        # RandomForest
        rf = build_random_forest()
        rf_pipe = build_pipeline(rf, feature_cols)
        with st.spinner("RandomForest í•™ìŠµ ì¤‘..."):
            rf_pipe.fit(X_train, y_train)
        rf_metrics = evaluate_binary(rf_pipe, X_test, y_test)
        results.append(("RandomForest", rf_pipe, rf_metrics))

        # XGBoost (ìˆìœ¼ë©´)
        neg = (y_train == 0).sum()
        pos = (y_train == 1).sum()
        xgb = try_build_xgboost(neg / pos)
        if xgb is None:
            st.warning("XGBoost ë¯¸ì„¤ì¹˜ë¡œ ìŠ¤í‚µí–ˆìŠµë‹ˆë‹¤. í•„ìš” ì‹œ: pip install xgboost")
        else:
            xgb_pipe = build_pipeline(xgb, feature_cols)
            with st.spinner("XGBoost í•™ìŠµ ì¤‘..."):
                xgb_pipe.fit(X_train, y_train)
            xgb_metrics = evaluate_binary(xgb_pipe, X_test, y_test)
            results.append(("XGBoost", xgb_pipe, xgb_metrics))

        # ê²°ê³¼ í‘œ
        rows = []
        for name, _, m in results:
            rows.append({
                "model": name,
                "accuracy": m["accuracy"],
                "precision": m["precision"],
                "recall": m["recall"],
                "f1": m["f1"],
                "auc": m["auc"],
            })
        res_df = pd.DataFrame(rows).sort_values(metric_pick, ascending=False).reset_index(drop=True)
        st.dataframe(res_df, use_container_width=True)


        st.subheader("ëª¨ë¸ë³„ Recall / F1 ë¹„êµ")

        plot_df = res_df.set_index("model")[["recall", "f1"]]

        fig = plt.figure(figsize=(7, 4))
        plot_df.plot(kind="bar", ax=plt.gca())
        plt.ylim(0, 1)
        plt.ylabel("score")
        plt.title("Model Performance Comparison (Recall & F1)")
        plt.xticks(rotation=0)
        plt.grid(axis="y", alpha=0.3)
        plt.tight_layout()
        st.pyplot(fig)
        st.caption(
            "Recallì€ ì¤‘ëŒ€ì‚¬ê³ ë¥¼ ë†“ì¹˜ì§€ ì•ŠëŠ” ëŠ¥ë ¥, "
            "F1ì€ Recallê³¼ Precisionì˜ ê· í˜•ì„ ì˜ë¯¸í•©ë‹ˆë‹¤."
        )

        st.subheader("ëª¨ë¸ë³„ AUC ë¹„êµ")

        auc_df = res_df.set_index("model")[["auc"]]

        fig = plt.figure(figsize=(6, 4))
        auc_df.plot(kind="bar", ax=plt.gca(), legend=False)
        plt.ylim(0, 1)
        plt.ylabel("AUC")
        plt.title("Model Performance Comparison (AUC)")
        plt.xticks(rotation=0)
        plt.grid(axis="y", alpha=0.3)
        plt.tight_layout()
        st.pyplot(fig)

        st.caption(
            "AUCëŠ” ì„ê³„ê°’ê³¼ ë¬´ê´€í•˜ê²Œ ëª¨ë¸ì˜ ì „ì²´ì ì¸ ë¶„ë¥˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” ì§€í‘œì…ë‹ˆë‹¤."
        )
        
        # best ëª¨ë¸ ì €ì¥(ì„¸ì…˜ì—)
        best_name = res_df.loc[0, "model"]
        best_pipe, best_metrics = None, None
        for name, pipe, m in results:
            if name == best_name:
                best_pipe, best_metrics = pipe, m
                break

        st.session_state["model"] = best_pipe
        st.session_state["model_name"] = best_name
        st.session_state["model_metrics"] = best_metrics
        st.session_state["feature_cols"] = feature_cols
        st.session_state["compare_table"] = res_df

        st.success(f"Best ëª¨ë¸: **{best_name}** (ê¸°ì¤€: {metric_pick})")

        # Confusion Matrix
        cm = best_metrics["confusion_matrix"]
        fig = plt.figure(figsize=(4, 3))
        plt.imshow(cm)
        plt.title(f"Confusion Matrix ({best_name})")
        plt.xlabel("Pred")
        plt.ylabel("True")
        for (i, j), v in np.ndenumerate(cm):
            plt.text(j, i, str(v), ha="center", va="center")
        plt.tight_layout()
        st.pyplot(fig)

    # ì´ë¯¸ í•™ìŠµëœ ê²°ê³¼ê°€ ìˆìœ¼ë©´ í‘œì‹œ
    if "compare_table" in st.session_state:
        st.divider()
        st.write("**ìµœê·¼ í•™ìŠµ ê²°ê³¼(ì„¸ì…˜)**")
        st.dataframe(st.session_state["compare_table"], use_container_width=True)

# =========================================================
# 4) ì˜ˆì¸¡
# =========================================================
with t4:
    st.subheader("ë‹¨ê±´ ì˜ˆì¸¡ / ë°°ì¹˜ ì˜ˆì¸¡")

    if "model" not in st.session_state or st.session_state["model"] is None:
        st.warning("ë¨¼ì € [3) ëª¨ë¸ í•™ìŠµ/ì„±ëŠ¥ ë¹„êµ] ë˜ëŠ” [6) ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸°]ì—ì„œ ëª¨ë¸ì„ ì¤€ë¹„í•˜ì„¸ìš”.")
    else:
        model = st.session_state["model"]
        feature_cols = st.session_state.get("feature_cols", DEFAULT_FINAL_COLS)
        feature_cols = [c for c in feature_cols if c in acc.columns]

        st.write("### â‘  ë‹¨ê±´ ì˜ˆì¸¡")
        input_row = {}
        cols = st.columns(3)
        for i, c in enumerate(feature_cols):
            opts = sorted(acc[c].dropna().astype(str).unique().tolist())
            if "ë¯¸ìƒ" not in opts:
                opts = ["ë¯¸ìƒ"] + opts
            input_row[c] = cols[i % 3].selectbox(c, opts, index=0, key=f"pred_{c}")

        X_one = pd.DataFrame([input_row])

        if st.button("ğŸ” ì˜ˆì¸¡ ì‹¤í–‰", type="primary"):
            pred = int(model.predict(X_one)[0])
            proba = None
            if hasattr(model, "predict_proba"):
                try:
                    proba = float(model.predict_proba(X_one)[:, 1][0])
                except Exception:
                    proba = None

            st.write(f"ì˜ˆì¸¡ ê²°ê³¼(ì¤‘ëŒ€ì‚¬ê³ ): **{pred}**")
            if proba is not None:
                st.write(f"ì¤‘ëŒ€ì‚¬ê³  í™•ë¥ : **{proba:.3f}**")

        st.divider()
        st.write("### â‘¡ CSV ë°°ì¹˜ ì˜ˆì¸¡")
        up = st.file_uploader("ì˜ˆì¸¡ìš© CSV ì—…ë¡œë“œ", type=["csv"])
        if up is not None:
            df_in = pd.read_csv(up)
            need = [c for c in feature_cols if c in df_in.columns]
            if len(need) != len(feature_cols):
                st.error("ì—…ë¡œë“œ CSVì— í•„ìš”í•œ feature ì»¬ëŸ¼ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.")
                st.write("í•„ìš” ì»¬ëŸ¼:", feature_cols)
            else:
                Xb = df_in[feature_cols].copy()
                for c in feature_cols:
                    Xb[c] = Xb[c].astype(object).fillna("ë¯¸ìƒ")

                pred_b = model.predict(Xb)
                out = df_in.copy()
                out["pred_ì¤‘ëŒ€ì‚¬ê³ "] = pred_b

                if hasattr(model, "predict_proba"):
                    try:
                        out["proba_ì¤‘ëŒ€ì‚¬ê³ "] = model.predict_proba(Xb)[:, 1]
                    except Exception:
                        pass

                st.dataframe(out.head(30), use_container_width=True)
                st.download_button(
                    "ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
                    data=out.to_csv(index=False).encode("utf-8-sig"),
                    file_name="predictions.csv",
                    mime="text/csv",
                )

# =========================================================
# 5) Feature Importance
# =========================================================
with t5:
    st.subheader("Feature Importance (One-Hot ê¸°ì¤€)")

    if "model" not in st.session_state or st.session_state["model"] is None:
        st.warning("ë¨¼ì € [3) ëª¨ë¸ í•™ìŠµ/ì„±ëŠ¥ ë¹„êµ]ì—ì„œ ëª¨ë¸ì„ í•™ìŠµí•˜ê±°ë‚˜ [6) ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸°]ë¡œ ë¡œë“œí•˜ì„¸ìš”.")
    else:
        model_pipe = st.session_state["model"]
        feature_cols = st.session_state.get("feature_cols", DEFAULT_FINAL_COLS)
        feature_cols = [c for c in feature_cols if c in acc.columns]

        imp_df, col_imp = compute_feature_importance(model_pipe, feature_cols)

        c1, c2 = st.columns([1, 1])
        with c1:
            st.write("**ì›ë³¸ ì»¬ëŸ¼ ë‹¨ìœ„ ì¤‘ìš”ë„ í•©(ì¶”ì²œ)**")
            st.dataframe(col_imp, use_container_width=True)

            topn = st.slider("ì»¬ëŸ¼ ì¤‘ìš”ë„ ê·¸ë˜í”„ Top-N", 3, 20, 10, 1)
            plot_df = col_imp.head(topn).sort_values("model_importance")
            fig = plt.figure(figsize=(7, 4))
            plt.barh(plot_df["base_col"], plot_df["model_importance"])
            plt.title(f"ì»¬ëŸ¼ ì¤‘ìš”ë„ Top {topn}")
            plt.xlabel("importance(í•©)")
            plt.tight_layout()
            st.pyplot(fig)

        with c2:
            st.write("**One-Hot í”¼ì²˜ ë‹¨ìœ„ ì¤‘ìš”ë„(ìƒìœ„)**")
            st.dataframe(imp_df.head(30), use_container_width=True)

            topn2 = st.slider("One-Hot ì¤‘ìš”ë„ ê·¸ë˜í”„ Top-N", 5, 30, 15, 1)
            plot2 = imp_df.head(topn2).sort_values("importance")
            fig2 = plt.figure(figsize=(8, 5))
            plt.barh(plot2["feature"], plot2["importance"])
            plt.title(f"One-Hot Feature Importance Top {topn2}")
            plt.xlabel("importance")
            plt.tight_layout()
            st.pyplot(fig2)

        st.caption("â€» LogisticRegressionì˜ ê²½ìš° |coef| ê¸°ë°˜ ì¤‘ìš”ë„(ì ˆëŒ€ê°’), RandomForest/XGBoostëŠ” feature_importances_ ê¸°ë°˜ì…ë‹ˆë‹¤.")

# =========================================================
# 6) ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸°
# =========================================================
with t6:
    st.subheader("ëª¨ë¸ ì €ì¥ ë° ë¶ˆëŸ¬ì˜¤ê¸°")

    st.write("í˜„ì¬ ëª¨ë¸ ìƒíƒœ:")
    if "model" in st.session_state and st.session_state["model"] is not None:
        st.success(f"- ë¡œë“œë¨: {st.session_state.get('model_name', '(unknown)')}")
        if "model_metrics" in st.session_state and st.session_state["model_metrics"] is not None:
            m = st.session_state["model_metrics"]
            st.write(f"- f1={m['f1']:.3f}, auc={m['auc']:.3f} (NaNì¼ ìˆ˜ ìˆìŒ), recall={m['recall']:.3f}")
        st.write("- feature_cols:", st.session_state.get("feature_cols", DEFAULT_FINAL_COLS))
    else:
        st.warning("- ì•„ì§ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. [3) ëª¨ë¸ í•™ìŠµ/ì„±ëŠ¥ ë¹„êµ]ì—ì„œ í•™ìŠµí•˜ê±°ë‚˜ ì €ì¥ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ì„¸ìš”.")

    c1, c2, c3 = st.columns([1, 1, 2])

    with c1:
        if st.button("ğŸ’¾ best_model.pkl ì €ì¥", type="primary"):
            if "model" not in st.session_state or st.session_state["model"] is None:
                st.warning("ì €ì¥í•  ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € í•™ìŠµ/ë¡œë“œí•˜ì„¸ìš”.")
            else:
                joblib.dump(st.session_state["model"], MODEL_PATH)
                st.success(f"ì €ì¥ ì™„ë£Œ: {MODEL_PATH}")

    with c2:
        if st.button("ğŸ“¦ ì €ì¥ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°"):
            if MODEL_PATH.exists():
                m = joblib.load(MODEL_PATH)
                st.session_state["model"] = m
                st.session_state["model_name"] = "best_model.pkl(loaded)"
                st.session_state["model_path"] = str(MODEL_PATH)
                st.success("ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ!")
            else:
                st.warning("ì €ì¥ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì €ì¥í•˜ì„¸ìš”.")

    with c3:
        st.write("ëª¨ë¸ íŒŒì¼ ìœ„ì¹˜:", str(MODEL_PATH))
        st.write("models í´ë”:", str(MODELS_DIR))
